# Oya Environment Configuration

# Path to the repository to document (defaults to current directory)
# REPO_PATH=/path/to/your/repo

# LLM Provider Configuration
# Uncomment ONE of the following provider configurations:

# OpenAI
# OPENAI_API_KEY=sk-...
# ACTIVE_PROVIDER=openai
# ACTIVE_MODEL=gpt-4o

# Anthropic
# ANTHROPIC_API_KEY=sk-ant-...
# ACTIVE_PROVIDER=anthropic
# ACTIVE_MODEL=claude-3-5-sonnet-20241022

# Google
# GOOGLE_API_KEY=...
# ACTIVE_PROVIDER=google
# ACTIVE_MODEL=gemini-1.5-pro

# Ollama (local, no API key needed)
# ACTIVE_PROVIDER=ollama
# ACTIVE_MODEL=llama2
# OLLAMA_ENDPOINT=http://host.docker.internal:11434
