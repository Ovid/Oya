# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Ọya is a local-first, editable wiki generator for codebases. It uses LLMs to generate documentation from source code.

**Storage:** Wikis stored in `~/.oya/wikis/{local_path}/` with `source/` (git clone) and `meta/` (wiki artifacts) subdirectories

### Language-Agnostic Design

Ọya analyzes arbitrary codebases in any programming language. While we have specialized tree-sitter parsers for some languages (Python, TypeScript, Java), the system is designed to work with any language via the fallback parser.

**Critical rules:**
- **Never assume a repository's language.** Repositories contain multiple languages (e.g., Python backend + TypeScript frontend + shell scripts + config files).
- **Language-specific code paths require discovery.** Check file extensions, detect from parsing, or use the language field in `ParsedFile`. Never hardcode assumptions.
- **The fallback parser handles unknown languages.** It extracts what it can without language-specific AST knowledge.
- **When designing features, think language-agnostically first.** Only add language-specific behavior when the generic approach fails and you've confirmed the target language.

This is especially important when using Oya to analyze itself—don't assume the target repo uses Python/FastAPI/React just because Oya does.

## Development Commands

### Backend (Python/FastAPI)

```bash
cd backend
source .venv/bin/activate  # Uses existing venv
pip install -e ".[dev]"    # Install with dev dependencies

# Run server
uvicorn oya.main:app --reload

# Run tests
pytest                      # All tests
pytest tests/test_qa_api.py # Single file
pytest -k "test_name"       # By name pattern
```

**API Documentation (auto-generated by FastAPI):**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc
- OpenAPI JSON: http://localhost:8000/openapi.json

### Frontend (React/TypeScript/Vite)

```bash
cd frontend
npm install
npm run dev      # Dev server on :5173
npm run build    # TypeScript check + Vite build
npm run lint     # ESLint
npm run test     # Vitest (run once)
npm run test:watch  # Vitest (watch mode)
```

### Docker

```bash
docker-compose up  # Runs both services
```

## Architecture

### Backend Structure (`backend/src/oya/`)

- **api/routers/**: FastAPI endpoints (repos, repos_v2, wiki, jobs, search, qa, notes)
- **db/**: SQLite for job tracking, metadata, and repo registry
  - `repo_registry.py`: Multi-repo CRUD operations
- **generation/**: Wiki generation pipeline
  - `orchestrator.py`: Main generation coordinator - handles the full pipeline
  - `prompts.py`: All LLM prompt templates
  - `synthesis.py`: Combines parsed code into documentation
  - `summaries.py`: Hierarchical code summarization
  - `staging.py`: Atomic wiki updates via staging directory
- **llm/**: LiteLLM-based client supporting OpenAI, Anthropic, Google, Ollama
- **parsing/**: Tree-sitter based code parsers (Python, TypeScript, Java, fallback)
- **repo/**: Repository management
  - `url_parser.py`: Parse git URLs and detect source type
  - `git_operations.py`: Clone/pull wrappers with error handling
  - `repo_paths.py`: Directory structure utilities for multi-repo storage
- **vectorstore/**: ChromaDB for semantic search and Q&A
- **notes/**: Human correction system

### Frontend Structure (`frontend/src/`)

- **components/**: React components
  - `Layout.tsx`, `Sidebar.tsx`, `TopBar.tsx`: Shell UI
  - `RepoDropdown.tsx`: Repository selector with status indicators
  - `AddRepoModal.tsx`: Add new repository modal
  - `FirstRunWizard.tsx`: Welcome screen for first-time setup
  - `GenerationProgress.tsx`: Real-time job progress via SSE
  - `IndexingPreviewModal.tsx`: File selection before generation
  - `QADock.tsx`: Q&A interface
  - `pages/`: Route components (Overview, Architecture, Workflow, Directory, File)
- **stores/**: Zustand state management
  - `reposStore.ts`: Multi-repo state (list, active repo, CRUD)
  - `wikiStore.ts`: Wiki tree and page content
  - `generationStore.ts`: Job tracking and progress
  - `uiStore.ts`: UI state (panels, modals)
- **api/**: Typed API client functions

### Data Flow

1. User triggers generation → `POST /api/repos/init`
2. Backend creates job, starts async generation via `orchestrator.py`
3. Progress streamed via SSE at `/api/jobs/{id}/stream`
4. Wiki written to `.oyawiki-building/` (staging), then atomically promoted to `.oyawiki/`
5. Frontend polls `/api/wiki/tree` and renders markdown pages

### Wiki Generation Pipeline

The pipeline runs in `orchestrator.py` (main coordinator, ~66KB) through 7 sequential phases:

1. **Analysis** (`_run_analysis`) - Parse files using tree-sitter parsers → `ParsedFile` with symbols, imports, references
2. **Files** (`_run_files`) - Generate markdown for each file → `FileSummary` extracted from LLM response
3. **Directories** (`_run_directories`) - Aggregate FileSummaries into directory docs
4. **Synthesis** (`_run_synthesis`) - Combine all summaries → `SynthesisMap` with layers, entry points, patterns
5. **Architecture** (`_run_architecture`) - Generate architecture.md using SynthesisMap
6. **Overview** (`_run_overview`) - Generate overview.md with project description
7. **Workflows** (`_run_workflows`) - Trace entry points through call graph

**Key data flow:**
- `ParsedFile` → (parsing) symbols, references with confidence scores
- `Reference` → (graph/builder.py) edges in call graph (nodes.json, edges.json)
- `FileSummary` → (from LLM) structured data extracted from file page generation
- `SynthesisMap` → (synthesis) combined view used by architecture/overview/workflows

**Incremental regeneration:** Files are content-hashed. Unchanged files skip regeneration unless `--full-regeneration` is passed.

**Graph module (`oya/graph/`):**
- `builder.py` - Builds networkx graph from parsed references
- `query.py` - Query functions (get_call_sites, get_callers, find_unused)
- `persistence.py` - Load/save nodes.json, edges.json

When modifying parsing (extracting new reference types), remember:
- References need correct `source` scope (e.g., `file.py::ClassName.method`, not just `file.py`)
- Graph nodes use these scopes as IDs; mismatched scopes break edge creation

### Key Patterns

- **Settings**: Loaded via `config.py:load_settings()` from env vars, cached with `@lru_cache`
- **LLM calls**: All go through `llm/client.py`, logged to `.oya-logs/llm-queries.jsonl`
- **Tests**: pytest with `asyncio_mode = "auto"`, hypothesis for property testing
- **Staging**: Generation writes to `.oyawiki-building/`, promotes atomically on success

### Configuration Constants

Hard-coded values that control application behavior are extracted to config files for easier tuning and documentation.

**Backend:** Configuration is centralized in `backend/src/oya/config.py` with the `CONFIG_SCHEMA` dictionary defining all settings with defaults and validation. Access via `load_settings().section.property`:
- `settings.generation` - LLM temperatures, chunking parameters
- `settings.ask` - Q&A token budgets, confidence thresholds, CGRAG settings
- `settings.llm` - Default LLM client settings
- `settings.search` - Result limits, deduplication
- `settings.files` - File size limits, concurrency
- `settings.paths` - Directory names

**Frontend:** `frontend/src/config/`
- `layout.ts` - Panel dimensions, z-index layers
- `qa.ts` - Confidence level colors
- `timing.ts` - Polling intervals, relative time thresholds

### localStorage

All Oya data is stored under a single `oya` key in localStorage. The storage module (`frontend/src/utils/storage.ts`) handles all access with automatic snake_case conversion.

**Key conventions:**
- All property names use `snake_case` in storage
- Runtime TypeScript types use `camelCase`
- Conversion happens at the storage boundary

**Storage structure:**
```typescript
{
  dark_mode: boolean,
  ask_panel_open: boolean,
  sidebar_left_width: number,
  sidebar_right_width: number,
  current_job: { job_id, status, ... } | null,
  qa_settings: { quick_mode, temperature, timeout_minutes },
  generation_timing: { [job_id]: { job_id, job_started_at, phases } }
}
```

**Usage:**
```typescript
import { getStorageValue, setStorageValue } from '../utils/storage'

// Read
const darkMode = getStorageValue('darkMode')

// Write
setStorageValue('darkMode', true)
```

Do not access localStorage directly. Always use the storage module.

## Architectural Discipline

Before implementing new functionality:
1. Search for existing utilities/helpers that do similar things
2. Check if the pattern exists elsewhere in the codebase
3. If implementing something common (date formatting, error handling, API calls, validation), assume it already exists and search first

When modifying files:
- Imports go at module top, not inside functions
- If a class exceeds ~10 attributes or ~15 methods, consider splitting

### Before Writing "General Purpose" Code

When about to write something that feels reusable:
- Utility functions (formatting, parsing, validation)
- API/HTTP helpers
- Error handling patterns
- Data transformation logic
- UI components (buttons, modals, form elements)

**Stop and search first:**
1. Grep for similar function names or keywords
2. Check obvious locations (utils/, helpers/, common/, shared/, lib/)
3. Look at how similar features were implemented elsewhere in the codebase

If found: reuse or extend existing code.
If close but not quite: refactor existing rather than duplicate.

### Code Review: Architectural Checks

When reviewing code (your own or others'), check for these flaws:

**Import Placement**: Flag imports inside functions/methods. These should be at module top unless avoiding a circular import.

**God Object Detection**: If a class exceeds 10 attributes or 15 public methods, evaluate cohesion:
- Do all attributes/methods serve ONE clear responsibility?
- Would you struggle to describe the class's purpose in one sentence?
- Are there subsets of methods that only use subsets of attributes?
- Legitimate large classes: data containers, facades, protocol implementations, test fixtures
- Flag as issue only if incoherent, not merely large

**Duplication Review**: If similar code appears multiple times:
- Is this test code? (Often acceptable)
- Is this the second occurrence? (Wait for third before abstracting)
- Would abstracting create a confusing helper with too many parameters?
- Flag only if: 3+ occurrences AND abstraction would be cleaner

**Missing Reuse**: Check if new helpers duplicate existing infrastructure in the codebase.

## Environment Variables

- `OYA_DATA_DIR`: Directory for storage (default: `~/.oya`)

LLM config (auto-detected from available keys):
- `ACTIVE_PROVIDER`: openai | anthropic | google | ollama
- `ACTIVE_MODEL`: Model name (has provider-specific defaults)
- Provider API keys: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `GOOGLE_API_KEY`
- `OLLAMA_ENDPOINT`: Defaults to `http://localhost:11434`

## Code Style

- Backend: Python 3.11+, ruff for linting, line length 100
- Frontend: TypeScript strict, ESLint, Tailwind CSS

## Testing Requirements

**TDD is mandatory.** Follow red/green/refactor for all code changes where tests are possible:

1. **Red** - Write a failing test that defines the expected behavior
2. **Green** - Write minimal code to make the test pass
3. **Refactor** - Clean up while keeping tests green

This applies to:
- New features
- Bug fixes (write a test that reproduces the bug first)
- Refactoring (ensure existing tests cover the behavior, add tests if not)

**Deviations require explicit user approval.** If you believe TDD doesn't apply to a specific change, ask before proceeding. Valid exceptions are rare (e.g., pure config changes, documentation-only changes).

**Running tests:**
```bash
# Backend
cd backend && source .venv/bin/activate
pytest                          # All tests
pytest tests/test_file.py -v    # Single file
pytest -k "test_name" -v        # By pattern
pytest --tb=short               # Shorter tracebacks

# Frontend
cd frontend
npm run test                    # Run once
npm run test:watch              # Watch mode
```

**Test locations:**
- Backend: `backend/tests/test_*.py`
- Frontend: `frontend/src/**/*.test.ts(x)`

## Error Handling

### Never Silently Discard Errors
Errors that disappear make debugging impossible. Every error must either:
1. **Propagate** - Let it bubble up to a handler that can deal with it
2. **Log** - Record what went wrong with context (file, operation, relevant data)
3. **Transform** - Convert to a user-visible error state or message

### Catch Specific Exceptions
```python
# BAD - catches everything including bugs
except Exception:
    pass

# GOOD - catches what you expect
except (FileNotFoundError, PermissionError) as e:
    logger.warning(f"Could not read {path}: {e}")
```

### When Generic Except is Acceptable
Only in these cases, and MUST include a comment explaining why:
1. **Resource cleanup in finally/close()** - Best-effort cleanup where failure doesn't matter
2. **Graceful degradation** - Feature works without this, AND you log the fallback
3. **Top-level handlers** - API endpoints, CLI entry points that must not crash

### Required Documentation for `pass` in Except
If you must use `pass`, the comment must explain:
- What errors are expected
- Why ignoring them is safe
- What the fallback behavior is

```python
# ACCEPTABLE - documented, specific scenario
except sqlite3.OperationalError:
    # Column already exists from previous migration - safe to ignore
    pass

# UNACCEPTABLE - no explanation
except Exception:
    pass
```

### Distinguish "No Results" from "Query Failed"
Never return empty collections on error - this hides failures:
```python
# BAD - caller can't tell if search failed or found nothing
except Exception:
    return []

# GOOD - caller knows something went wrong
except ChromaDBError as e:
    logger.error(f"Vector search failed: {e}")
    raise SearchError(f"Search unavailable: {e}") from e
```